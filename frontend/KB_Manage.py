import os
import time
from math import ceil
import pandas as pd
import streamlit as st


def get_unique_files_info(ref_doc_info):
    docs = []
    seen_paths = set()

    for ref_doc_id, ref_doc in ref_doc_info.items():

        metadata = ref_doc.metadata
        file_path = metadata.get('file_path', None)

        if file_path is None:
            title = metadata.get('title', None)
            url = metadata.get('url_source', None)
            docs.append({
                'id': ref_doc_id,
                'name': title,
                'type': "url",
                'path': url,
                'date': metadata['creation_date']
            })

        if file_path and file_path not in seen_paths:
            base_name, extension = os.path.splitext(metadata['file_name'])
            # Remove the leading dot from the extension
            extension = extension.lstrip('.')

            file_info = {
                'id': ref_doc_id,
                'name': base_name,
                'type': extension,
                'path': file_path,
                # 'file_size': metadata['file_size'],
                'date': metadata['creation_date']
            }
            docs.append(file_info)
            seen_paths.add(file_path)

    return docs


def handle_knowledgebase():
    st.header("è¿›è¡Œæ–‡ä»¶ç®¡ç†")
    st.caption("ç®¡ç†çŸ¥è¯†åº“ä¸­çš„æ–‡æ¡£ã€‚ï¼ˆåœ¨å‰é¢è¿›è¡Œé€‰æ‹©ã€‚éƒ¨åˆ†æ–°åŠ è½½çš„æ–‡æ¡£å¯èƒ½éœ€è¦é‡å¯æ‰èƒ½ç”Ÿæ•ˆã€‚ï¼‰")

    from server.stores.strage_context import STORAGE_CONTEXT
    doc_store = STORAGE_CONTEXT.docstore
    if len(doc_store.docs) > 0:
        ref_doc_info = doc_store.get_all_ref_doc_info()
        unique_files = get_unique_files_info(ref_doc_info)
        st.write("ä¸€å…±æœ‰ï¼š", len(unique_files), "ä¸ªæ–‡ä»¶.")
        df = pd.DataFrame(unique_files)

        # Pagination settings

        page_size = 10
        total_pages = ceil(len(df) / page_size)

        if "curr_page" not in st.session_state.keys():
            st.session_state.curr_page = 1

        curr_page = min(st.session_state['curr_page'], total_pages)

        # Displaying pagination buttons
        if total_pages > 1:
            prev, next, _, col3 = st.columns([1, 1, 6, 2])

            if next.button("ä¸‹ä¸€é¡µ"):
                curr_page = min(curr_page + 1, total_pages)
                st.session_state['curr_page'] = curr_page

            if prev.button("ä¸Šä¸€é¡µ"):
                curr_page = max(curr_page - 1, 1)
                st.session_state['curr_page'] = curr_page

            with col3:
                st.write("å½“å‰é¡µ/æ€»é¡µæ•°: ", curr_page, "/", total_pages)

        start_index = (curr_page - 1) * page_size
        end_index = curr_page * page_size
        df_paginated = df.iloc[start_index:end_index]

        # Displaying the paginated dataframe
        docs = st.dataframe(
            df_paginated,
            width=2000,
            column_config={
                "id": None,  # hidden
                "name": "åç§°",
                "type": "æ ¼å¼",
                "path": None,
                "date": "ä¸Šä¼ æ—¥æœŸ",

            },
            hide_index=True,
            on_select="rerun",
            selection_mode="multi-row",
        )

        selected_docs = docs.selection.rows
        if len(selected_docs) > 0:
            delete_button = st.button("åˆ é™¤é€‰ä¸­çš„æ–‡ä»¶", key="delete_docs")
            if delete_button:
                print("Deleting documents...")
                with st.spinner(text="æ­£åœ¨åˆ é™¤æ–‡æ¡£å’Œç›¸å…³ç´¢å¼•ã€‚è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿçš„æ—¶é—´ã€‚"):
                    for item in selected_docs:
                        path = df_paginated.iloc[item]['path']
                        for ref_doc_id, ref_doc in ref_doc_info.items():  # a file may have multiple documents
                            metadata = ref_doc.metadata
                            file_path = metadata.get('file_path', None)
                            if file_path:
                                if file_path == path:
                                    st.session_state.index_manager.delete_ref_doc(ref_doc_id)
                            elif metadata.get('url_source', None) == path:
                                st.session_state.index_manager.delete_ref_doc(ref_doc_id)
                    st.toast('âœ”ï¸ é€‰æ‹©çš„æ–‡æ¡£å·²åˆ é™¤ï¼', icon='ğŸ‰')
                    time.sleep(4)
                    st.rerun()

            st.write("é€‰ä¸­çš„æ–‡ä»¶:")
            for item in selected_docs:
                st.write(f"- {df_paginated.iloc[item]['name']}")

    else:
        st.write("çŸ¥è¯†åº“ä¸ºç©ºï¼å‰å¾€â€˜æ–‡ä»¶ä¸Šä¼ â€™é¡µé¢ä¸Šä¼ æ–‡ä»¶ï¼")


handle_knowledgebase()


